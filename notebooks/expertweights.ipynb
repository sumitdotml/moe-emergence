{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fc70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612307a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5858, 0.4142],\n",
       "         [0.4547, 0.5453],\n",
       "         [0.7196, 0.2804],\n",
       "         [0.7319, 0.2681],\n",
       "         [0.5072, 0.4928],\n",
       "         [0.5598, 0.4402],\n",
       "         [0.2730, 0.7270],\n",
       "         [0.4512, 0.5488],\n",
       "         [0.1884, 0.8116],\n",
       "         [0.3390, 0.6610],\n",
       "         [0.0505, 0.9495],\n",
       "         [0.8895, 0.1105]]),\n",
       " tensor([[3, 0],\n",
       "         [1, 6],\n",
       "         [4, 0],\n",
       "         [2, 1],\n",
       "         [1, 0],\n",
       "         [3, 3],\n",
       "         [4, 5],\n",
       "         [3, 6],\n",
       "         [6, 5],\n",
       "         [4, 0],\n",
       "         [0, 6],\n",
       "         [4, 3]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(11)\n",
    "\n",
    "batch = 2\n",
    "sqlen = 6\n",
    "hidden_dim = 16\n",
    "topk = 2\n",
    "experts = 8\n",
    "\n",
    "x = torch.randn(batch, sqlen, hidden_dim)\n",
    "x_flat = x.view(-1, hidden_dim) # [12, 16]\n",
    "\n",
    "def renormalization(input: Tensor) -> Tensor:\n",
    "        total = input.sum(\n",
    "            dim=-1, keepdim=True\n",
    "        )  # total sum of experts' raw scores, not token count, hence -1 dim\n",
    "        renormalized = input / total  # [batch*seqlen, topk]\n",
    "        return renormalized\n",
    "\n",
    "weights = renormalization(torch.rand(batch*sqlen, topk))\n",
    "indices = torch.randint(0, 7, [batch*sqlen, topk])\n",
    "\n",
    "weights, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde05c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  2,  4,  9, 10]), tensor([1, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total weight being received\n",
    "expert_load_0 = torch.where(indices==0)\n",
    "token_idx, topk_idx = expert_load_0\n",
    "token_idx, topk_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa62cea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8990)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_0_weights_summed = sum([(weights[i][j]) for i, j in zip(token_idx, topk_idx)])\n",
    "expert_0_weights_summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f31001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_load_balance_loss(weights, indices):\n",
    "    total_tokens, topk_experts = weights.shape\n",
    "    results = []\n",
    "    for i in range(experts):\n",
    "        token_idx, topk_idx = torch.where(indices==i)\n",
    "        expert_i_weights_summed = weights[token_idx, topk_idx].sum()\n",
    "        results.append(expert_i_weights_summed)\n",
    "    print(f\"Results:\\n{results}\")\n",
    "    expert_loads = torch.stack(results)\n",
    "    print(f\"results with torch.stack:\\n{expert_loads}\")\n",
    "    expert_load_fractions = expert_loads / total_tokens\n",
    "    load_variance = torch.var(expert_load_fractions)\n",
    "    return load_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87662de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "[tensor(1.8990), tensor(1.2300), tensor(0.7319), tensor(2.1475), tensor(2.2211), tensor(1.5386), tensor(2.2319), tensor(0.)]\n",
      "results with torch.stack:\n",
      "tensor([1.8990, 1.2300, 0.7319, 2.1475, 2.2211, 1.5386, 2.2319, 0.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0045)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = compute_load_balance_loss(weights, indices)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f92141e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand(2, 6, 16)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae53c0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 16])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape(-1, 16).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10c371a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 4096]), Linear(in_features=4096, out_features=8, bias=False))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_router = nn.Linear(4096, 8, bias=False)\n",
    "W_router.weight.shape, W_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34524768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4096])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "\n",
    "x_in = torch.randn(2, 6, 4096)\n",
    "x_flattened = x_in.reshape(-1, 4096)\n",
    "x_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cda8ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 8]),\n",
       " tensor([[ 1.4361,  0.5818, -0.3305, -1.5377,  0.5158, -0.7169, -0.0205, -0.4584],\n",
       "         [ 0.0093,  0.6592, -0.3625,  1.0004,  0.6719, -0.3256,  0.1337, -0.0865],\n",
       "         [-0.8257, -0.4223,  1.2087,  0.3993, -1.1458, -0.2525,  0.3592, -1.1005],\n",
       "         [ 0.5657,  0.8405, -0.6680, -0.0194, -0.4599,  0.6501, -0.3727, -0.1869],\n",
       "         [-0.0244,  0.6992,  0.5910, -1.7488,  0.0191,  0.6949,  0.4897,  0.5927],\n",
       "         [ 0.4651,  0.7655,  0.1293,  0.8185, -0.0651, -0.2502,  0.7604, -0.9779],\n",
       "         [ 0.3417,  0.2140,  0.4174, -0.3592,  0.5346, -0.2904, -0.8432, -0.0372],\n",
       "         [ 0.5197, -0.8920,  0.0574,  0.4456,  0.2165, -0.2069,  0.1237, -0.3281],\n",
       "         [ 0.2653, -0.2304,  0.1694,  0.0213, -0.4691,  0.0512,  0.1946,  0.4519],\n",
       "         [-0.2691, -0.6196, -0.2924, -0.2852, -0.2254, -0.4779, -0.2580, -1.1385],\n",
       "         [-0.6962, -0.7461,  0.1406, -0.0272, -0.2004,  0.5228, -0.1185,  1.0816],\n",
       "         [ 0.0731,  1.0642,  0.7293, -0.1455,  0.3779,  1.0956,  0.1346,  0.3392]],\n",
       "        grad_fn=<MmBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_matrix = W_router(x_flattened)\n",
    "router_matrix.shape, router_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ee8594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8]),\n",
       " tensor([ 0.5657,  0.8405, -0.6680, -0.0194, -0.4599,  0.6501, -0.3727, -0.1869],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_matrix[3].shape, router_matrix[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "695035d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_router.weight[3, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59efda25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4096, 8]),\n",
       " tensor([[-0.0043,  0.0086,  0.0075,  ..., -0.0029, -0.0094,  0.0082],\n",
       "         [-0.0087, -0.0008,  0.0036,  ..., -0.0107,  0.0113,  0.0142],\n",
       "         [ 0.0052,  0.0141, -0.0129,  ...,  0.0122,  0.0016,  0.0136],\n",
       "         ...,\n",
       "         [-0.0141, -0.0149,  0.0123,  ..., -0.0124, -0.0023, -0.0058],\n",
       "         [-0.0099,  0.0108, -0.0073,  ...,  0.0148,  0.0040,  0.0107],\n",
       "         [ 0.0009,  0.0099,  0.0082,  ...,  0.0104,  0.0116, -0.0101]],\n",
       "        grad_fn=<PermuteBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_router.weight.T.shape, W_router.weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "414707cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4361,  0.5818, -0.3305, -1.5377,  0.5158, -0.7169, -0.0205, -0.4584],\n",
       "        [ 0.0093,  0.6592, -0.3625,  1.0004,  0.6719, -0.3256,  0.1337, -0.0865],\n",
       "        [-0.8257, -0.4223,  1.2087,  0.3993, -1.1458, -0.2525,  0.3592, -1.1005],\n",
       "        [ 0.5657,  0.8405, -0.6680, -0.0194, -0.4599,  0.6501, -0.3727, -0.1869],\n",
       "        [-0.0244,  0.6992,  0.5910, -1.7488,  0.0191,  0.6949,  0.4897,  0.5927],\n",
       "        [ 0.4651,  0.7655,  0.1293,  0.8185, -0.0651, -0.2502,  0.7604, -0.9779],\n",
       "        [ 0.3417,  0.2140,  0.4174, -0.3592,  0.5346, -0.2904, -0.8432, -0.0372],\n",
       "        [ 0.5197, -0.8920,  0.0574,  0.4456,  0.2165, -0.2069,  0.1237, -0.3281],\n",
       "        [ 0.2653, -0.2304,  0.1694,  0.0213, -0.4691,  0.0512,  0.1946,  0.4519],\n",
       "        [-0.2691, -0.6196, -0.2924, -0.2852, -0.2254, -0.4779, -0.2580, -1.1385],\n",
       "        [-0.6962, -0.7461,  0.1406, -0.0272, -0.2004,  0.5228, -0.1185,  1.0816],\n",
       "        [ 0.0731,  1.0642,  0.7293, -0.1455,  0.3779,  1.0956,  0.1346,  0.3392]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x_flattened, W_router.weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155116dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = torch.randn(12, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "242e268c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx - xxx.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24e33b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step: 0\n",
      "Anneal steps: 2500\n"
     ]
    }
   ],
   "source": [
    "class Router(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, n_ffn_experts: int, topk: int, noise_std: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.W_router = nn.Linear(hidden_dim, n_ffn_experts, bias=False)\n",
    "        self.register_buffer(\"training_step\", torch.tensor(0, dtype=torch.long))\n",
    "        self.register_buffer(\"anneal_steps\", torch.tensor(0, dtype=torch.long))\n",
    "\n",
    "    def set_noise_annealing(self, total_steps: int, anneal_fraction: float = 0.25):\n",
    "        self.anneal_steps.fill_(int(total_steps * anneal_fraction))\n",
    "\n",
    "\n",
    "\n",
    "router = Router(hidden_dim=4096, n_ffn_experts=8, topk=2)\n",
    "router.set_noise_annealing(total_steps=10000, anneal_fraction=0.25)\n",
    "print(f\"Training step: {router.training_step}\")\n",
    "print(f\"Anneal steps: {router.anneal_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744c26c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
