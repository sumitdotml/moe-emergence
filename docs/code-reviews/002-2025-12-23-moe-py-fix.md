# Fix Report: moe.py Code Review Issues

**Date:** 2025-12-23
**Fix Commit:** `eea9294`
**Review Reference:** `001-2025-12-23-moe-py-review.md`
**Previous Commit:** `31252b6`

---

## Summary

All issues identified in the 2025-12-23 code review have been resolved. The fixes were verified with lint checks and smoke tests.

---

## Fixes Applied

### H1: Added `router_probs_clean` and `entropy` to RouterOutput [HIGH]

**Problem:** Router only returned noisy probabilities, confounding entropy analysis with noise annealing.

**Solution:**

1. Compute clean probabilities and entropy BEFORE adding noise
2. Add both fields to RouterOutput NamedTuple
3. Update all unpacking sites across 3 files

**Files Changed:**

- `moe.py:8-18` - RouterOutput definition
- `moe.py:143-148` - Compute clean probs and entropy
- `moe.py:272-279` - Updated return statement
- `moe.py:390-398` - Updated MoE.forward() unpacking
- `gpt2_moe.py:25-35` - MoEWrapperOutput definition
- `gpt2_moe.py:126-133` - MoEWrapper.forward() unpacking
- `gpt2_moe.py:140-147` - self.last_aux assignment
- `training_demo.py:222-230` - Updated unpacking

**Before:**

```python
class RouterOutput(NamedTuple):
    topk_weights: Tensor
    topk_indices: Tensor
    router_probs: Tensor      # noisy during annealing
    router_logits: Tensor
```

**After:**

```python
class RouterOutput(NamedTuple):
    topk_weights: Tensor
    topk_indices: Tensor
    router_probs: Tensor        # post-noise, for load balancing
    router_probs_clean: Tensor  # pre-noise, for entropy logging
    router_logits: Tensor
    entropy: Tensor             # computed from clean probs
```

---

### M1: Fixed Noise Docstring [MEDIUM]

**Problem:** Docstring implied noise_std is active by default, but anneal_steps=0 disables it.

**Solution:** Updated docstring to clarify opt-in behavior.

**File Changed:** `moe.py:46-47`

**Before:**

```python
noise_std: Standard deviation of noise to add to logits (default 0.1)
```

**After:**

```python
noise_std: Standard deviation for NoisyTop-k routing. Noise is only active
    after calling set_noise_annealing(). (default 0.1)
```

---

### M2: STE Training Mode Check [MEDIUM]

**Problem:** STE was applied unconditionally, including during inference.

**Solution:** Wrapped STE in training mode check.

**File Changed:** `moe.py:261-265`

**Before:**

```python
soft = topk_weights
hard = torch.ones_like(soft)
topk_weights = hard + (soft - soft.detach())  # STE
```

**After:**

```python
soft = topk_weights
hard = torch.ones_like(soft)
if self.training:
    topk_weights = hard + (soft - soft.detach())  # STE during training
else:
    topk_weights = hard  # No STE overhead during inference
```

---

### L1: Replaced .view() with .reshape() [LOW]

**Problem:** `.view()` fails on non-contiguous tensors.

**Solution:** Changed to `.reshape()` which handles non-contiguous tensors.

**Files Changed:**

- `moe.py:136` - Router.forward()
- `moe.py:387` - MoE.forward()

---

### L3: Fixed Load Balancing Docstring [LOW]

**Problem:** "fraction of tokens routed" was imprecise for top-k > 1.

**Solution:** Clarified wording.

**File Changed:** `moe.py:415-416`

**Before:**

```python
- f_i: fraction of tokens ROUTED to expert i (hard assignment from top-k)
```

**After:**

```python
- f_i: fraction of total routing assignments to expert i (for top-k routing,
      each token contributes k assignments, so sum of f_i = 1.0)
```

---

## Verification

### Lint Check

```
$ uv run ruff check moe-emergence/
All checks passed!
```

### Format

```
$ uv run ruff format moe-emergence/
4 files reformatted, 1 file left unchanged
```

### Smoke Test

```
$ uv run python moe-emergence/training_demo.py

Key outputs:
- Gradient norm: 0.0227 (>0 means router is learning) ✓
- Balance loss: ~1.0 (target) ✓
- Expert utilization: 21-28% each (balanced) ✓
- Z-loss bounded ✓
```

---

## Remaining Work

None. All issues from the original review have been addressed.

---

## References

- Previous review: `001-2025-12-23-moe-py-review.md`
- V3 Design spec: `project-design/MOE-PROJECT-DESIGN-V3.md`
- GPT-5.2 review: `MODELS-DEBATE.md`
